{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer, BertForMaskedLM, AdamW, BertConfig, BertForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make training & validation set with toeic part5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Part5_training.txt', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "training, val = train_test_split(dataset, test_size = 0.1, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4666"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 64\n",
    "toeic_training = []\n",
    "\n",
    "for pset in training:\n",
    "    q = pset['question'].strip().lower()\n",
    "    ans = pset['answer'].strip().lower()\n",
    "    for j in range(1, 5):\n",
    "        if pset[str(j)].strip().lower() == ans:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        sentence = re.sub('_', ' '+pset[str(j)]+' ', q).lower()\n",
    "        \n",
    "        input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "        attn_mask = [1]*len(input_ids) + [0]*(max_len - len(input_ids))\n",
    "        input_ids = input_ids + [0]*(max_len-len(input_ids))\n",
    "        segment_ids = [0] * max_len\n",
    "        if label == 1:\n",
    "            for _ in range(3):\n",
    "                toeic_training.append([input_ids, segment_ids, attn_mask, label])\n",
    "        else:\n",
    "            toeic_training.append([input_ids, segment_ids, attn_mask, label])\n",
    "random.shuffle(toeic_training)\n",
    "\n",
    "\n",
    "toeic_val = []\n",
    "\n",
    "for pset in val:\n",
    "    q = pset['question'].strip().lower()\n",
    "    ans = pset['answer'].strip().lower()\n",
    "    for j in range(1, 5):\n",
    "        if pset[str(j)].strip().lower() == ans:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        sentence = re.sub('_', ' '+pset[str(j)]+' ', q).lower()\n",
    "        input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "        attn_mask = [1]*len(input_ids) + [0]*(max_len - len(input_ids))\n",
    "        input_ids = input_ids + [0]*(max_len-len(input_ids))\n",
    "        segment_ids = [0] * max_len\n",
    "        toeic_val.append([input_ids, segment_ids, attn_mask, label])\n",
    "random.shuffle(toeic_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27996"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(toeic_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size : 16, num of batch_train : 1750, num of batch_validation : 130\n"
     ]
    }
   ],
   "source": [
    "input_ids, segment_ids, attn_mask, label = zip(*toeic_training)\n",
    "input_ids = torch.LongTensor(input_ids)\n",
    "segment_ids = torch.LongTensor(segment_ids)\n",
    "label = torch.LongTensor(label)\n",
    "attn_mask = torch.LongTensor(attn_mask)\n",
    "input_ids_loader = torch.utils.data.DataLoader(input_ids, batch_size=16)\n",
    "segment_ids_loader = torch.utils.data.DataLoader(segment_ids, batch_size=16)\n",
    "label_loader = torch.utils.data.DataLoader(label, batch_size=16)\n",
    "attn_mask_loader = torch.utils.data.DataLoader(attn_mask, batch_size=16)\n",
    "\n",
    "#validation\n",
    "input_ids_val, segment_ids_val, attn_mask_val, label_val = zip(*toeic_val)\n",
    "input_ids_val = torch.LongTensor(input_ids_val)\n",
    "segment_ids_val = torch.LongTensor(segment_ids_val)\n",
    "label_val = torch.LongTensor(label_val)\n",
    "attn_mask_val = torch.LongTensor(attn_mask_val)\n",
    "input_ids_loader_val = torch.utils.data.DataLoader(input_ids_val, batch_size=16)\n",
    "segment_ids_loader_val = torch.utils.data.DataLoader(segment_ids_val, batch_size=16)\n",
    "label_loader_val = torch.utils.data.DataLoader(label_val, batch_size=16)\n",
    "attn_mask_loader_val = torch.utils.data.DataLoader(attn_mask_val, batch_size=16)\n",
    "\n",
    "print('batch size : 16, num of batch_train : {}, num of batch_validation : {}'.format(len(input_ids_loader), len(input_ids_loader_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning BertForSequenceClassification model(bert_grammer) with toeic part5 questions(4666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_grammer = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "bert_grammer.cuda()\n",
    "\n",
    "optimizer = AdamW(bert_grammer.parameters(),\n",
    "                  lr =1e-5, \n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "epochs = 5\n",
    "\n",
    "#number of batches * epochs = total number of training step\n",
    "total_steps = len(input_ids_loader) * epochs\n",
    "#create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "  Batch   300  of  1,750.\n",
      "  Batch   600  of  1,750.\n",
      "  Batch   900  of  1,750.\n",
      "  Batch 1,200  of  1,750.\n",
      "  Batch 1,500  of  1,750.\n",
      "\n",
      "Average training loss: 0.51\n",
      "\n",
      "Running Validaiton...\n",
      "Validation loss decreased ( inf --> 0.450405). Saving model ...\n",
      "Average validation loss: 0.45\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "  Batch   300  of  1,750.\n",
      "  Batch   600  of  1,750.\n",
      "  Batch   900  of  1,750.\n",
      "  Batch 1,200  of  1,750.\n",
      "  Batch 1,500  of  1,750.\n",
      "\n",
      "Average training loss: 0.32\n",
      "\n",
      "Running Validaiton...\n",
      "EarlyStopping counter: 1 out of 2\n",
      "Average validation loss: 0.65\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "  Batch   300  of  1,750.\n",
      "  Batch   600  of  1,750.\n",
      "  Batch   900  of  1,750.\n",
      "  Batch 1,200  of  1,750.\n",
      "  Batch 1,500  of  1,750.\n",
      "\n",
      "Average training loss: 0.32\n",
      "\n",
      "Running Validaiton...\n",
      "EarlyStopping counter: 2 out of 2\n",
      "Average validation loss: 0.63\n",
      "Early stopping executed\n",
      "Finetuning Bert for grammer is finished!\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "early_stopping = EarlyStopping(verbose = True)\n",
    "for epoch in range(0, epochs):\n",
    "    \n",
    "    #train\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
    "    print('Training...')\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    bert_grammer.train()\n",
    "    step = 0\n",
    "    for input_ids, segment_ids, label, attn_mask in zip(input_ids_loader, segment_ids_loader, label_loader, attn_mask_loader):\n",
    "        \n",
    "        if step % 300 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(input_ids_loader)))\n",
    "        step += 1\n",
    "        input_ids = input_ids.to('cuda')\n",
    "        segment_ids = segment_ids.to('cuda')\n",
    "        label = label.to('cuda')\n",
    "        attn_mask = attn_mask.to('cuda')\n",
    "        bert_grammer.zero_grad()\n",
    "        outputs = bert_grammer(input_ids=input_ids ,token_type_ids=segment_ids, labels = label, attention_mask = attn_mask)\n",
    "        clf_loss = outputs[0]\n",
    "        train_loss += clf_loss.item()\n",
    "        clf_loss.backward()\n",
    "        \n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(bert_grammer.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        #Update the learning rate.\n",
    "        scheduler.step()\n",
    "        \n",
    "    avg_train_loss = train_loss / len(input_ids_loader)\n",
    "    loss_train.append(avg_train_loss)\n",
    "    print(\"\")\n",
    "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "\n",
    "    # validation\n",
    "    print(\"\")\n",
    "    print('Running Validaiton...')\n",
    "    bert_grammer.eval()\n",
    "    \n",
    "    for input_ids_val, segment_ids_val, label_val, attn_mask_val in zip(input_ids_loader_val, segment_ids_loader_val, label_loader_val, attn_mask_loader_val):\n",
    "        input_ids_val = input_ids_val.to('cuda')\n",
    "        segment_ids_val = segment_ids_val.to('cuda')\n",
    "        label_val = label_val.to('cuda')\n",
    "        attn_mask_val = attn_mask_val.to('cuda')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = bert_grammer(input_ids=input_ids_val ,token_type_ids=segment_ids_val, labels = label_val, attention_mask = attn_mask_val)\n",
    "        clf_loss_val = outputs[0]\n",
    "        val_loss += clf_loss_val.item()\n",
    "    avg_val_loss = val_loss / len(input_ids_loader_val)\n",
    "    loss_val.append(avg_val_loss)\n",
    "    \n",
    "    early_stopping(avg_val_loss, bert_grammer)\n",
    "    print(\"Average validation loss: {0:.2f}\".format(avg_val_loss))\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping executed\")\n",
    "        break\n",
    "        \n",
    "    bert_grammer.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    \n",
    "print(\"Finetuning Bert for grammer is finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test models with toeic part5 915 questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get score of Finetuned SequenceClassification model(bert_grammer)\n",
    "def get_logit(model, input_ids, segment_ids):\n",
    "    input_ids_tensor = torch.tensor(input_ids).unsqueeze(0).to('cuda')\n",
    "    segment_ids_tensor = torch.tensor(segment_ids).to('cuda')\n",
    "    outputs = model(input_ids = input_ids_tensor, token_type_ids = segment_ids_tensor)\n",
    "    logit =outputs[0][0][1]\n",
    "\n",
    "    return logit.item()\n",
    "\n",
    "#function to get score or pretrained BertForMaskedLM from \n",
    "def get_score(model, tokenizer, question_tensors, segment_tensors, masked_index, candidate):\n",
    "    \n",
    "    question_tensors = torch.tensor(question_tensors).unsqueeze(0).to('cuda')\n",
    "    segment_tensors = torch.tensor(segment_tensors).to('cuda')\n",
    "\n",
    "    candidate_tokens = tokenizer.tokenize(candidate) # warranty -> ['warrant', '##y']\n",
    "    candidate_ids = tokenizer.convert_tokens_to_ids(candidate_tokens)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_ids = question_tensors, token_type_ids = segment_tensors)\n",
    "        predictions_candidates = predictions[0][0][masked_index][candidate_ids].mean()\n",
    "\n",
    "    return predictions_candidates.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "915 Toeic part5 questions are loaded! Our model will solve 915 questions like below.\n",
      "\n",
      "=================================================Quesiton Example==================================================\n",
      "question : Since this is still under [ ? ] , you should return it to the manufacturer to be repaired.\n",
      "answer : warranty\n",
      "1 : warranty\n",
      "2 : promise\n",
      "3 : debate\n",
      "4 : requirement\n",
      "\n",
      "\n",
      "==================================================Predictions Example==================================================\n",
      "                Correct answer                 Pretrained BertForMaskedLM     Finetuned BertForSeqClf       \n",
      "Question1       used                           used                           used                          \n",
      "Question2       showed                         showed                         showed                        \n",
      "Question3       competitive                    competitive                    competitive                   \n",
      "Question4       decrease                       decrease                       decrease                      \n",
      "Question5       that                           that                           that                          \n",
      "Question6       upon                           upon                           upon                          \n",
      "Question7       transfers                      transfers                      transfers                     \n",
      "Question8       project                        project                        project                       \n",
      "Question9       rather than                    as well                        rather than                   \n",
      "Question10      does                           does                           does                          \n",
      "Question11      whether                        whether                        how                           \n",
      "Question12      that he not stay               staying not                    that he not stay              \n",
      "Question13      give                           give                           give                          \n",
      "Question14      hub                            hub                            destination                   \n",
      "Question15      praised                        praised                        praised                       \n",
      "Question16      to report                      to report                      to report                     \n",
      "Question17      should                         should                         should                        \n",
      "Question18      encouragement                  encouragement                  encouragement                 \n",
      "Question19      who                            who                            who                           \n",
      "Question20      realistically                  realistic                      realistically                 \n",
      ".\n",
      ".\n",
      ".\n",
      "Testing 100 in 915\n",
      "Testing 200 in 915\n",
      "Testing 300 in 915\n",
      "Testing 400 in 915\n",
      "Testing 500 in 915\n",
      "Testing 600 in 915\n",
      "Testing 700 in 915\n",
      "Testing 800 in 915\n",
      "Testing 900 in 915\n",
      "=================================================Test finished=================================================\n",
      "\n",
      "Pretrained BertForMaskedLM : 0.8382513661202186\n",
      "Finetuned BertForSequenceClassification(Bert_grammer) : 0.8775956284153006\n"
     ]
    }
   ],
   "source": [
    "#Testing BertForMaskedLM(only pretrained) + BertForSequenceClassification(Grammer finetuned)\n",
    "bert_lm = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "bert_lm.cuda()\n",
    "bert_lm.eval()\n",
    "bert_grammer.eval()\n",
    "cnt_bert_mixed = 0\n",
    "cnt_bert_base = 0\n",
    "cnt_bert_grammer = 0\n",
    "\n",
    "with open('Part5_test.txt', 'rb') as f:\n",
    "    testset = pickle.load(f)\n",
    "random.shuffle(testset)\n",
    "\n",
    "print(f'\\n{len(testset)} Toeic part5 questions are loaded! Our model will solve {len(testset)} questions like below.\\n')\n",
    "print('=================================================Quesiton Example==================================================')\n",
    "for k, v in testset[random.randrange(1, len(testset))].items():\n",
    "    if k == 'question':\n",
    "        v = re.sub('_', '[ ? ]', v)\n",
    "    print(f'{k} : {v}')\n",
    "print('\\n')\n",
    "for i, pset in enumerate(testset):\n",
    "    \n",
    "    grammer_score = []\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(\"Testing {} in {}\".format(i+1, len(testset)))\n",
    "    q = pset['question'].lower()\n",
    "    ans = pset['answer'].lower() \n",
    "    sentence_lm = re.sub('_', ' [MASK] ', q)\n",
    "    input_ids_lm = tokenizer.encode(sentence_lm, add_special_tokens=True)\n",
    "    masked_index_lm = input_ids_lm.index(103)\n",
    "    segment_ids_lm = [0] * len(input_ids_lm)\n",
    "    lm_score = [get_score(bert_lm, tokenizer, input_ids_lm, segment_ids_lm, masked_index_lm, pset[str(j)])  for j in range(1, 5)]\n",
    "    \n",
    "    for k in range(1, 5):\n",
    "        sentence_grammer = re.sub('_', ' '+pset[str(k)]+' ', q).lower()\n",
    "        input_ids_grammer = tokenizer.encode(sentence_grammer, add_special_tokens=True)\n",
    "        segment_ids_grammer = [0] * len(input_ids_grammer)\n",
    "        grammer_score.append(get_logit(bert_grammer, input_ids_grammer, segment_ids_grammer))\n",
    "    \n",
    "    softmax = torch.nn.Softmax(dim=0)\n",
    "    pred_tunedModel = np.argmax(grammer_score)+1\n",
    "    pred_baseModel = torch.argmax(softmax(torch.tensor(lm_score))).item()+1\n",
    "    \n",
    "        \n",
    "    if pset[str(pred_tunedModel)].lower() == ans:\n",
    "        cnt_bert_grammer += 1\n",
    "    if pset[str(pred_baseModel)].lower() == ans:\n",
    "        cnt_bert_base += 1\n",
    "\n",
    "    if 0<= i < 20:\n",
    "        if i == 0:\n",
    "            print('==================================================Predictions Example==================================================')\n",
    "            print('{0:15s} {1:<30s} {2:<30s} {3:<30s}'.format('','Correct answer', 'Pretrained BertForMaskedLM', 'Finetuned BertForSeqClf'))\n",
    "        print('{0:15s} {1:<30s} {2:<30s} {3:<30s}'.format('Question'+str(i+1), ans, pset[str(pred_baseModel)].lower(), pset[str(pred_tunedModel)].lower()))\n",
    "    if i == 20:\n",
    "        print('.\\n.\\n.')\n",
    "print('=================================================Test finished=================================================\\n')\n",
    "print('Pretrained BertForMaskedLM : {}\\nFinetuned BertForSequenceClassification(Bert_grammer) : {}'.format(cnt_bert_base/len(testset), cnt_bert_grammer/len(testset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
